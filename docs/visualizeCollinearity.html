<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Visualizing Collinearity</title>
    <link rel="stylesheet" href="style.css">
    <!-- Mathjax -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <!-- Polyfill needed only for IE11 -->
    <script id="MathJax-script" async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    <!-- /Mathjax -->
    <script src="toc.js"></script>
  </head>
<body class="statsnotes">
  <div class="content">
    <section id="introduction">
      <h1>Visualizing Collinearity</h1>
      <p>
        While there are many resources out there to describe the issues arising
        with multicollinearity in independent variables, there’s a visualization
        for the problem that I came across in a book once and haven’t found
        replicated online. This replicates the visualization.
      </p>
    </section>
    <section id="set-up">
      <h2>Set-up</h2>
      <p>
        Let \(Y\) be a response and \(X_1\) and \(X_2\) be the predictors, such
        that
      </p>

      \[
      Y_i = \beta_0 + \beta_1X_{1i} + \beta_2X_{2i} + \epsilon_i
      \]

      <p>
        for individual \(i\).
      </p>

      <p>
        For simplicity, let’s say that
      </p>

      \[
      \beta_0 = 0,\\ \beta_1 = 1,\\ \beta_2 = 1.
      \]

      <p>
        I carry out a simulation by generating 1,000 data-sets with a specific
        correlation between predictors and obtain their coefficients.
      </p>

  <pre>reps <span class="operator"><-</span> <span class="numeric">1000</span>
n <span class="operator"><-</span> <span class="numeric">100</span>
save <span class="operator"><-</span> <span class="keyword">matrix</span>(<span class="keyword">nrow</span> <span class="operator">=</span> reps, <span class="keyword">ncol</span> <span class="operator">=</span> <span class="numeric">3</span>)

<span class="keyword">for</span> (i <span class="keyword">in</span> <span class="numeric">1</span><span class="operator">:</span>reps) {
  x1 <span class="operator"><-</span> <span class="keyword">rnorm</span>(n)
  x2 <span class="operator"><-</span> <span class="keyword">rnorm</span>(n)
  y <span class="operator"><-</span> x1 <span class="operator">+</span> x2 <span class="operator">+</span> <span class="keyword">rnorm</span>(n)

  mod <span class="operator"><-</span> <span class="keyword">lm</span>(y <span class="operator">~</span> x1 <span class="operator">+</span> x2)
  save[i, ] <span class="operator"><-</span> <span class="keyword">c</span>(<span class="keyword">coef</span>(mod)[<span class="numeric">-1</span>], <span class="keyword">cor</span>(x1, x2))
}</pre>

      <p>
        The line <code>x2 &lt;- rnorm(n)</code> gets replaced with <code>x2
        &lt;- x1 + rnorm(n, sd = _)</code>, where the <code>_</code> is replaced
        with difference values to induce more correlation
        between <code>x1</code> and <code>x2</code>.
      </p>
    </section>
    <section id="simulation">
      <h2>Simulation Results</h2>


      <label>
        <input
          type="radio"
          name="collinearity_strength"
          value="low"
          checked
          onChange="updatePlot('data/lowcorr.json')"
          >
        Low
      </label>

      <label>
        <input
          type="radio"
          name="collinearity_strength"
          value="mod"
          onChange="updatePlot('data/modcorr.json')"
          >
        Moderate
      </label>

      <label>
        <input
          type="radio"
          name="collinearity_strength"
          value="high"
          onChange="updatePlot('data/highcorr.json')"
          >
        High
      </label>

      <label>
        <input
          type="radio"
          name="collinearity_strength"
          value="extreme"
          onChange="updatePlot('data/extremecorr.json')"
          >
        Extreme
      </label>


      <table style="border-collapse: collapse; width: 100%;">
        <tr>
          <td style="padding: 0; vertical-align: top; width: 60%;">
            <canvas id="myChart" width="600" height="450"></canvas>
          </td>
          <td style="padding: 0; vertical-align: top; width: 40%;
                     margin-top: 40px;">

            <p>
              Each point represents the estimated coefficients for a single
              simulated data set. The red dot represents the data-generating
              coefficients \((1, 1)\). Note that bias is not a concern; the true
              coefficients are on average for each level of collinearity.
            </p>

            <p>
              In this simulation, the average correlation between \(X_1\) and
              \(X_2\) is <span id="x1x2corr">0.002</span>.
            </p>


            <div id="lowText" class="text-container">
              With low correlation, we see no relationship between the estimated
              coefficients.
            </div>
            <div id="modText" class="text-container" style="display:none;">
              While we are starting to see a correlation between the
              coefficients, it is not that strong yet.
            </div>
            <div id="highText" class="text-container" style="display:none;">
              With correlation around .9, we are seeing very strong
              collinearity: if \(\hat{X_1}\) is low, then we would expect
              \(\hat{X_2}\) to be high.
            </div>
            <div id="extremeText" class="text-container" style="display:none;">
              This relationship is incredibly strong.
            </div>

          </td>
        </tr>
      </table>

    </section>
    <section id="why-is-this-a-problem">
      <h2>Why is this a problem?</h2>
      <p>
        So this simulation shows that at correlations around .9 or higher
        between \(X_1\) and \(X_2\), there is negative correlation between
        \(\hat{X_1}\) and \(\hat{X_2}\). Why is this a problem?
      </p>

      <p>
        Consider the “extremely high correlation” results. With such high
        correlation, we have that \(X_1 \approx X_2\). We can use this
        approximate equality to rewrite the model:
      </p>

      \[
      \begin{aligned} Y_i &amp;= \beta_0 + \beta_1X_{1i} + \beta_2X_{2i} +
      \epsilon_i\\ &amp;\approx \beta_0 + (\beta_1 + \beta_2)X_{1i} +
      \epsilon_i\\ &amp;\approx \beta_0 + (\beta_1 + \beta_2)X_{2i} + \epsilon_i
      \end{aligned}
      \]

      <p>
        In other words, the model has that \(\beta_1 + \beta_2 = 2\) (since we
        assumed above that both coefficients have values of 1). So while all of
        those models would have the same predictive power for \(Y\), they would
        have drastically different interpretations. For example, we could obtain
        \(\hat{X_1} = -1\) and \(\hat{X_2} = 3\), which not only over-emphasizes
        the relationship betwen \(X_2\) and \(Y\), but suggests a inverse
        relationship between \(X_1\) and \(Y\)!
      </p>
    </section>
    <img src="https://errickson.goatcounter.com/count?p=visualizeCollinearity">
  </div>
  <nav class="section-nav">
	  <ol>
		  <li class=""><a href="#introduction">Introduction</a></li>
		  <li class=""><a href="#set-up">Set-up</a></li>
		  <li class=""><a href="#simulation">Simulation</a></li>
		  <li class=""><a href="#why-is-this-a-problem">Why is this a Problem?</a></li>
    </ol>
    <script src="https://cdn.jsdelivr.net/npm/chart.js/dist/chart.umd.js"></script>
    <script src="plot.js"></script>
    <script src="corrtext.js"></script>
    <p style="text-align:center">
      <a href="https://errickson.net">Home</a> | <a href="https://errickson.net/stats-notes">Back</a>
    </p>
	</nav>
  <div class="showhide">
    <button id="showhideTOC" type="button">Hide TOC</button>
  </div>

</body>
</html>
